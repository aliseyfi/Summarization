{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPt743WCL8WKamBvhKjW46",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Summarization/blob/master/summarization_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe_SA3n0I3T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.neural_network import MLPRegressor as mlp\n",
        "from IPython.display import display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTagdmneHA5f",
        "colab_type": "code",
        "outputId": "319cbeb3-16e6-442d-96c7-97e1928c14bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1g4I5ARGTp",
        "colab_type": "code",
        "outputId": "abf1febd-b3e7-4cc0-ca20-804f2da73c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKpe_KPRLrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change to path to dataset\n",
        "file_name = \"/content/drive/My Drive/Summarization_Pickled_Data/cnn_dataset_1000_labelled.pkl\"\n",
        "stories = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpKVZKCERXbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# displaying the first datapoint\n",
        "# verify correctness of load\n",
        "\n",
        "# Uncomment to Display the First Datapoint\n",
        "# print(stories[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsEbuI08RZ9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Required Models for glove\n",
        "# in case of errors with conda, use this:\n",
        "# conda install -c conda-forge spacy\n",
        "# this is what worked for me :P\n",
        "\n",
        "# uncomment the next two lines if model data cannot be located\n",
        "!python -m spacy download en\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "!python -m spacy link en_core_web_lg en --force\n",
        "\n",
        "# use the large model as the default model for English textual data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-_iuFDvZTvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the processor\n",
        "embedder = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEsDrJHUTOxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic embeddings using averaged glove vectors\n",
        "# using Spacy's large language model\n",
        "def get_embedding(text):\n",
        "    extract = embedder(text)\n",
        "    total_sum = np.zeros(300)\n",
        "    count = 0\n",
        "    for token in extract:\n",
        "        count += 1\n",
        "        total_sum += np.asarray(token.vector)\n",
        "    return total_sum / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26X4T5jHRLpw",
        "colab_type": "code",
        "outputId": "26e5d76a-ef43-4f14-f88f-0587e57605dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# creating the inputs and expected outputs\n",
        "train_size = 900\n",
        "val_size = 50\n",
        "test_size = 50\n",
        "\n",
        "def make_set(start_index, size):\n",
        "    count = 0\n",
        "    X_set = []\n",
        "    y_set = []\n",
        "\n",
        "    for count in tqdm(range(size)):\n",
        "        data = stories[start_index + count]\n",
        "\n",
        "        doc_emb = get_embedding(data['story_text'])\n",
        "        # use the function of choice to generate the document embedding\n",
        "\n",
        "        index = 0\n",
        "        for sentence in data['story']:\n",
        "            sent_emb = get_embedding(sentence)\n",
        "            # use the function of choice to generate the sentence embedding\n",
        "\n",
        "            x = np.concatenate((sent_emb, doc_emb))\n",
        "            try:\n",
        "                y = data['scores'][index]\n",
        "            except:\n",
        "                y = 0.0\n",
        "            index += 1\n",
        "\n",
        "            X_set.append(x)\n",
        "            y_set.append(y)\n",
        "\n",
        "    return np.asmatrix(X_set), np.asarray(y_set)\n",
        "\n",
        "X_train, y_train = make_set(0, train_size)\n",
        "X_val, y_val = make_set(train_size, val_size)\n",
        "X_test, y_test = make_set(train_size + val_size, test_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [04:53<00:00,  3.06it/s]\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.54it/s]\n",
            "100%|██████████| 50/50 [00:15<00:00,  3.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY6JkXtWWOwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_values(X, model):\n",
        "    return model.predict(X)\n",
        "\n",
        "def get_loss(pred, y):\n",
        "    return np.linalg.norm(pred - y) / np.shape(y)[0]\n",
        "\n",
        "model_name = \"glove_averaged\"\n",
        "# modify the model name\n",
        "\n",
        "def make_parameters(train_size):\n",
        "    # uncomment to have batch size as a function of number of examples\n",
        "    # batch_size = int(np.sqrt(train_size))\n",
        "\n",
        "    # uncomment to have a constant batch size\n",
        "    batch_size = 256\n",
        "    n_batches = int(4 * (train_size / batch_size))\n",
        "    # can set batch_size to standard values such as 64, 128, 256\n",
        "\n",
        "    print(\"Total Number of Training Examples: \" + str(train_size))\n",
        "    print(\"Batch Size: \" + str(batch_size))\n",
        "    print(\"Number of Batches: \" + str(n_batches))\n",
        "\n",
        "    return batch_size, n_batches\n",
        "\n",
        "def train(X_train, y_train, batch_size, n_batches):\n",
        "    model = mlp(hidden_layer_sizes = (1024, 2048, 1024, 512, 256, 256, 128, 64), max_iter = 1000)\n",
        "    \n",
        "    train_size = np.shape(X_train)[0]\n",
        "\n",
        "    min_loss = 1e20\n",
        "\n",
        "    for iterator in tqdm(range(n_batches)):\n",
        "        idx = np.random.randint(0, train_size, size = batch_size)\n",
        "\n",
        "        X_select = X_train[idx,:]\n",
        "        y_select = y_train[idx]\n",
        "\n",
        "        model.partial_fit(X_select, y_select)\n",
        "\n",
        "        sentence_predicted_scores = get_values(X_val, model)\n",
        "\n",
        "        loss = get_loss(sentence_predicted_scores, y_val)\n",
        "\n",
        "        # saving best model seen so far\n",
        "        if loss < min_loss:\n",
        "            min_loss = loss\n",
        "            pickle.dump(model, open(model_name + '_best_model', 'wb'))\n",
        "\n",
        "    final_model = pickle.load(open(model_name + '_best_model', 'rb'))\n",
        "    return final_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrX21q4u8ukA",
        "colab_type": "code",
        "outputId": "0e490a83-ec6f-4b27-ea0c-72480c4ea92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "train_count = y_train.shape[0]\n",
        "batch_size, n_batches = make_parameters(train_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Training Examples: 19223\n",
            "Batch Size: 256\n",
            "Number of Batches: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzWH2VWaQjZ",
        "colab_type": "code",
        "outputId": "7b0eb6bd-945d-474b-f6be-c17bafa6f987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "m = train(X_train, 1000 * y_train, batch_size, n_batches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [04:36<00:00,  1.08it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl4yFkiyiTa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameter for similarity threshold\n",
        "theta = 0.95\n",
        "\n",
        "def similarity(A, B):\n",
        "    similarity =  (A @ B.T) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
        "    return similarity\n",
        "\n",
        "def get_top_k(X_doc, y, k):\n",
        "    # k should be in {3, 4, 5}\n",
        "    # error handling\n",
        "    k = int(k)\n",
        "    if k > 5:\n",
        "        k = 5\n",
        "    elif k < 3:\n",
        "        k = 3\n",
        "    \n",
        "    order = np.flip(np.argsort(y))\n",
        "    sentence_set = []\n",
        "    for sent_id in order:\n",
        "        if sentence_set == []:\n",
        "            sentence_set.append(order[0])\n",
        "            continue\n",
        "\n",
        "        consider = X_doc[sent_id, :]\n",
        "        flag = 1\n",
        "        for consider_id in sentence_set:\n",
        "            if similarity(X_doc[consider_id, :], consider) > theta:\n",
        "                flag = 0\n",
        "                break\n",
        "\n",
        "        if flag == 1:\n",
        "            sentence_set.append(sent_id)\n",
        "    return sentence_set[0: min(k, len(sentence_set))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_zjPWDVG179",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating object of the ROUGE class\n",
        "rouge = Rouge()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph6OFgGwcewS",
        "colab_type": "code",
        "outputId": "e8de3f40-de63-40c6-f086-1291b88fc9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# evaluation\n",
        "# testing out each document iteratively\n",
        "# test set: document 'train_size + val_size' onwards\n",
        "\n",
        "def join(lst):\n",
        "    string = \"\"\n",
        "    for elem in lst:\n",
        "        string = string + elem + \" . \"\n",
        "    return string\n",
        "\n",
        "def extract_rouge(rouge_dict):\n",
        "    scores = []\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['r'])\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['r'])\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['r'])\n",
        "\n",
        "    return np.asarray(scores)\n",
        "\n",
        "start_doc_id = train_size + val_size\n",
        "doc_count = len(stories)\n",
        "\n",
        "generated_summary, gold_summary = 0, 0\n",
        "# to access the final created summary\n",
        "\n",
        "# set the number of documents for testing\n",
        "limit = test_size\n",
        "\n",
        "result = {}\n",
        "result['3'] = np.zeros(9)\n",
        "result['4'] = np.zeros(9)\n",
        "result['5'] = np.zeros(9)\n",
        "# averaging the ROUGE Metrics\n",
        "# for different summary lengths\n",
        "\n",
        "count = 0\n",
        "all_summaries = []\n",
        "\n",
        "while count < min(doc_count, limit):\n",
        "    X_doc = []\n",
        "    y_doc = []\n",
        "    data = stories[start_doc_id + count]\n",
        "    doc_emb = get_embedding(data['story_text'])\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data['story']:\n",
        "        sent_emb = get_embedding(sentence)\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        try:\n",
        "            y = data['scores'][index]\n",
        "        except:\n",
        "            y = 0.0\n",
        "\n",
        "        index += 1\n",
        "\n",
        "        X_doc.append(x)\n",
        "        y_doc.append(y)\n",
        "\n",
        "    X_doc = np.asmatrix(X_doc)\n",
        "    y_doc = np.asarray(y_doc)\n",
        "\n",
        "    sentence_predicted_scores = get_values(X_doc, m)\n",
        "\n",
        "    loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "    # Uncomment to view the test_loss on the sample  \n",
        "    # print(loss)\n",
        "\n",
        "    gold_summary = join(data['highlights'])\n",
        "\n",
        "    for k in [3, 4, 5]:\n",
        "        summary_sent_id = get_top_k(X_doc, sentence_predicted_scores, k)\n",
        "        # Uncomment to view the indices of chosen sentences\n",
        "        # print(\"Document ID:\", start_doc_id + count, \", Top 5 Sentences:\", summary_sent_id)\n",
        "\n",
        "        # Uncomment to view the top 10 sentences based on Gold Labels\n",
        "        # print(\"Top 10 sentences based on Gold Label\", np.ndarray.tolist(np.flip(np.argsort(y_doc))[0:10]))\n",
        "\n",
        "        generated_summary = join([data['story'][idx] for idx in summary_sent_id])\n",
        "\n",
        "        scores = rouge.get_scores(generated_summary, gold_summary)[0]\n",
        "        result[str(k)] += extract_rouge(scores)\n",
        "\n",
        "    summary_eval = {'doc': data['story_text'], 'gen_summ': generated_summary, 'true_summ': gold_summary}\n",
        "    all_summaries.append(summary_eval)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "for k in [3, 4, 5]:\n",
        "    result[str(k)] = result[str(k)] / test_size\n",
        "\n",
        "predicted = get_values(X_test, m)\n",
        "test_loss = get_loss(y_test, predicted)\n",
        "\n",
        "print(\"Sample Output:\")\n",
        "print(\"Document:\\n\", stories[-1]['story_text'])\n",
        "print(\"Generated Summary:\\n\", generated_summary)\n",
        "print(\"Gold Summary:\\n\", gold_summary)\n",
        "\n",
        "print(\"\\nAll Metrics:\\n\")\n",
        "\n",
        "data = []\n",
        "for k in [3, 4, 5]:\n",
        "    lst = np.ndarray.tolist(result[str(k)])\n",
        "    lst.append(test_loss)\n",
        "    data.append(lst)\n",
        "\n",
        "df = pd.DataFrame(data, columns = ['R1-f', 'R1-p', 'R1-r',\n",
        "                                    'R2-f', 'R2-p', 'R2-r',\n",
        "                                    'Rl-f', 'Rl-p', 'Rl-r',\n",
        "                                    'Loss'], dtype = float)\n",
        "\n",
        "df.index = ['glove top-3', 'glove top-4', 'glove top-5']\n",
        "display(df)\n",
        "\n",
        "# save results into a dataframe file\n",
        "df.to_csv(model_name + '_results.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample Output:\n",
            "Document:\n",
            " -- in the wake of the earthquake in haiti, george clooney and other celebrities have signed on for a telethon to aid the devastated island nation..the oscar-winning actor will take part in a fundraising program to air commercial-free across several networks, mtv announced..\"hope for haiti now\" will air on abc, cbs, nbc, fox, cnn, bet, the cw, hbo, mtv, vh1 and cmt starting at 8 p.m. et/pt and 7 p.m. ct on friday, january 22..mtv said clooney will serve as a host in los angeles, while musician wyclef jean will be in new york, and cnn's anderson cooper will appear from haiti..the two-hour event will feature as-yet-unnamed musical performances and celebrity appearances, as well as live news reports from cnn..it's hollywood's latest philanthropic gesture in reaction to the catastrophic situation in haiti..a celebrity lounge at this weekend's golden globe awards in beverly hills has been turned into a haitian aid fundraiser..medecins sans frontieres says actors angelina jolie and brad pitt have donated $1 million to the group's emergency medical operation as it responds to the disaster..full coverage of the earthquake in haiti.tuesday's 7.0 earthquake has devastated the poverty-stricken country's infrastructure. haitian president rene preval said wednesday that he had heard estimates of up to 50,000 dead but that it was too early to know for sure..damage has closed the port and limited airport operations in the capital city of port-au-prince, and the quake buckled many roads, making it extremely difficult for aid groups to bring in emergency supplies and search for survivors in the rubble..mtv said all proceeds from the telethon will be split evenly among seven relief organizations currently operating in haiti: clinton-bush haiti fund, oxfam america, partners in health, the red cross, unicef and yele haiti foundation and world food programme..\n",
            "Generated Summary:\n",
            " full coverage of the earthquake in haiti . the two-hour event will feature as-yet-unnamed musical performances and celebrity appearances, as well as live news reports from cnn. . tuesday's 7.0 earthquake has devastated the poverty-stricken country's infrastructure. haitian president rene preval said wednesday that he had heard estimates of up to 50,000 dead but that it was too early to know for sure. . it's hollywood's latest philanthropic gesture in reaction to the catastrophic situation in haiti. . the oscar-winning actor will take part in a fundraising program to air commercial-free across several networks, mtv announced. . \n",
            "Gold Summary:\n",
            " fundraising program to be telecast on numerous networks on friday, january 22 . all proceeds will be split among five relief organizations . other celebrities have already launched efforts to aid quake-ravaged haiti . \n",
            "\n",
            "All Metrics:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R1-f</th>\n",
              "      <th>R1-p</th>\n",
              "      <th>R1-r</th>\n",
              "      <th>R2-f</th>\n",
              "      <th>R2-p</th>\n",
              "      <th>R2-r</th>\n",
              "      <th>Rl-f</th>\n",
              "      <th>Rl-p</th>\n",
              "      <th>Rl-r</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>glove top-3</th>\n",
              "      <td>18.274789</td>\n",
              "      <td>17.941758</td>\n",
              "      <td>25.297813</td>\n",
              "      <td>3.116467</td>\n",
              "      <td>2.990015</td>\n",
              "      <td>4.577814</td>\n",
              "      <td>18.427824</td>\n",
              "      <td>18.678011</td>\n",
              "      <td>23.298192</td>\n",
              "      <td>0.015503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>glove top-4</th>\n",
              "      <td>20.264442</td>\n",
              "      <td>16.856896</td>\n",
              "      <td>31.700668</td>\n",
              "      <td>4.077789</td>\n",
              "      <td>3.295410</td>\n",
              "      <td>6.585153</td>\n",
              "      <td>20.783930</td>\n",
              "      <td>18.030183</td>\n",
              "      <td>29.154959</td>\n",
              "      <td>0.015503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>glove top-5</th>\n",
              "      <td>20.384021</td>\n",
              "      <td>15.180150</td>\n",
              "      <td>36.328981</td>\n",
              "      <td>4.524013</td>\n",
              "      <td>3.305816</td>\n",
              "      <td>8.339549</td>\n",
              "      <td>21.130413</td>\n",
              "      <td>16.470445</td>\n",
              "      <td>33.204742</td>\n",
              "      <td>0.015503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  R1-f       R1-p       R1-r  ...       Rl-p       Rl-r      Loss\n",
              "glove top-3  18.274789  17.941758  25.297813  ...  18.678011  23.298192  0.015503\n",
              "glove top-4  20.264442  16.856896  31.700668  ...  18.030183  29.154959  0.015503\n",
              "glove top-5  20.384021  15.180150  36.328981  ...  16.470445  33.204742  0.015503\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yha_TYLBS3Ab",
        "colab_type": "code",
        "outputId": "92c49856-9119-4928-bf03-aa165df08583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# verifying creation of summaries\n",
        "print(all_summaries[0])\n",
        "\n",
        "filename = model_name + 'summaries_eval.pickle'\n",
        "# dumping summaries into a pickle file for further loading and evaluation\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(all_summaries, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'doc': 'philadelphia, pennsylvania (cnn) -- i wore a path between washington and philly for interviews and shoots for our recent \"cheating death\" special with dr. sanjay gupta..in the field: jeremy harlan.my job as a photojournalist is to shoot and edit stories for cnn and make sure my news team eats well on the road..on assignment: philadelphia, pennsylvania.now, i love cheese steaks as much as the next guy. but my arteries can only take so much steak, cheese and peppers. so here are a few places that are great alternatives in the city of brotherly love..reading terminal market.hours: 8 a.m.-6 p.m. monday through saturday; 9 a.m.-5 p.m. sunday.cuisine: you name it, the market has it.how do i describe the reading terminal market? it\\'s like the las vegas of food. everywhere you turn, there\\'s something interesting to see, smell and taste. it is food sensory overload..the hardest part of going to the market is not eating the very first thing you see. give yourself 15 minutes to walk through the market before deciding where to spend your hard-earned lunch dollar..i saw apple dumplings, muffalettas, spanakopita, pulled pork, snapper soup, strombolis, all the fresh veggies, meat and cheese you could throw in your fridge and of course cheese steaks..i finally decided to stop at dinic\\'s pork and beef for the famous roast pork sandwich. the service was fast and friendly. the sandwich was fantastic, and if you sit at the counter long enough, you might hear one of philly\\'s finest talk about the crazy arrest of the day..and make sure you save room for a smooth and creamy cupcake (or two) from the flying monkey..magic carpet.hours: 10:30 a.m.-3 p.m..cuisine: mediterranean/vegetarian.the first thing i ask our local contact on a story is where i\\'m eating lunch. if you ask holly auer, university of pennsylvania hospital\\'s senior medical communications officer, she\\'ll immediately say, \"magic carpet.\".this vegetarian culinary delight is actually a small vendor trailer just across from penn hospital. if you haven\\'t been to philly, you need to know this city takes its street vendor food pretty seriously..i still scratch my head at how these folks make so much delicious food in such cramped quarters. my personal favorite at magic carpet is a pita sandwich stuffed with grape leaves. it\\'s so good, i usually eat two..maybe the best part: the sandwiches are around five bucks. definitely the worst part: the long line of neurosurgeons, med students, nurses and cardiologists waiting for their delicious ride on the carpet, too..the franklin fountain.hours: noon-midnight.cuisine: ice cream.the franklin fountain is a cool escape back to the early 20th-century ice cream fountain shop. although it opened in the summer of 2004, you would think it was 1944 when you walk in the door. the owners left no detail ignored in building this dairy delight..the fountain offers sundaes, splits, ice cream waffle sandwiches, fresh pies, house-made cakes, phosphates and america\\'s oldest soft drink, just to name a few..coffee lovers will enjoy the lightning rod sundae. everyone will enjoy his or her trip back in time..', 'gen_summ': 'the hardest part of going to the market is not eating the very first thing you see. give yourself 15 minutes to walk through the market before deciding where to spend your hard-earned lunch dollar. . hours: 10:30 a.m.-3 p.m. . cuisine: you name it, the market has it . the franklin fountain . magic carpet . ', 'true_summ': 'cnn\\'s jeremy harlan talks about his favorite places to eat in philadelphia . reading terminal market is the \"las vegas of food,\" harlan says . franklin fountain is a cool escape back to early 20th-century soda fountain . '}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZx3VDg6Wm9M",
        "colab_type": "code",
        "outputId": "1274263d-7e7b-495e-8282-1a1b3fb9f83e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# verifying pickled file\n",
        "\n",
        "pickle_in = open(filename, \"rb\")\n",
        "eval_summ = pickle.load(pickle_in)\n",
        "\n",
        "# displaying the second summary\n",
        "print(all_summaries[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'doc': '-- vice president joe biden headlined a small catholic event wednesday in des moines, iowa, stoking speculation about his presidential aspirations..biden used most of his speech to tout nuns on the bus, a group of liberal catholic nuns who convey their message of social justice on road trips. but his praise for the group came in the form of stressing likely democratic issues in the midterm elections: the importance of health care and growth of the middle class..\"this nation is stronger when every voice is heard and everyone has a seat at the table,\" biden said on the steps of the iowa capitol. \"right now, only some of the voices are being heard, and as a result over the last couple of decades, things have gotten out of whack, folks.\".biden says use of \\'offensive\\' term shylock was a poor choice.to those in the audience, the presidential politics of the vice president\\'s visit were obvious. biden has admitted he is thinking about running for president, and a recent cnn/orc international poll found that 15% of iowa democrats would like him to be the democratic nominee in 2016..the vice president\\'s trip comes on the heels of hillary clinton\\'s much-talked about trip sunday to the harkin steak fry, the annual outdoor fund- raiser run by sen. tom harkin. the visit was clinton\\'s most obvious step toward a presidential run since leaving the state department in 2013. in the same cnn/orc poll, 53% of iowa democrats favored the former secretary of state..\"joe tells it like it is, and we are blessed to have him,\" said craig stark from clive, iowa, who said he hopes biden runs in 2016. as for how he feels about clinton, stark said, \"well, we don\\'t have dynasties like bush dynasties. ... to me we need new blood.\".the crowd also featured some of biden\\'s most ardent supporters from his short-lived 2008 presidential campaign..\"joe biden knows how to tell the truth, whether it is the politically correct thing to say or not,\" said john olsen, who proudly said he supported biden in the 2008 caucuses. \"you will become a fan of joe biden if you ever get a chance to meet him. he is the most personal, down-to-earth, lovable guy.\".clinton\\'s weekend visit was the first time she had been in iowa since 2008, but biden is no stranger to the hawkeye state..the vice president last visited a year ago when he spoke at the harkin steak fry, the most important annual event for iowa democrats that is widely seen as a must-stop for democrats considering a run at the white house..\"it\\'s amazing when you come to speak at the steak fry, a whole lot of people seem to take notice. i don\\'t know why the hell that is,\" biden joked then. \"you\\'ve attracted the entire national press corps here.\".biden has also made a point to acknowledge iowa on a regular basis..biden called john lundell, the new mayor of coralville, iowa, to congratulate him on his victory in november. and in may, biden stopped by a party of iowans in washington for a lobbying trip..wednesday\\'s speech was not biden\\'s only stop in iowa. during his visit, the vice president did a rope-line photo session with supporters of local democratic campaigns, including congressional ones, according to campaign sources in iowa. the photo session was seen as a perk for supporting local democrats..biden\\'s speech was the kickoff of the latest initiative from nuns on the bus in which the group will encourage voters in 36 cities along a 5,252-mile route to turn out and vote in the 2014 midterms..the vice president focused a great deal on what democrats are talking about ahead of the election: the poor and middle class..\"things are out of whack,\" biden said about the tax system in the united states. \"it comes down to a simple question of fairness. americans have always done best when we acted as one america. because when we do, the nation succeeds\".he added: \"it is time for a fair tax structure ... one that values hard work as much as inherited wealth. ... it is time to close these tax loopholes, folks.\".nuns on the bus was also active around the 2012 midterms. the group organized a multistate tour to bring attention to rep. paul ryan\\'s proposed budget cuts for medicare and other social welfare programs..sister simone campbell, executive director of the group behind the bus tour, told cnn that biden\\'s attendance was meant to encourage civic engagement but said the event was \"not partisan.\".\"right now, we are just doing what pope francis challenges us to do,\" campbell said. \"he says the heart of the problems of our society and our world is inequality and what we have to do is respond to the needs of the poor and those who are left out.\".campbell didn\\'t comment about biden\\'s presidential chances, but she said she had an idea about why he agreed to attend the nuns on the bus event..\"every time i have seen him, he tells me that catholic sisters help keep him catholic,\" she said with a laugh. \"i think part of the reason he is coming is his own nourishment and his support of us.\".', 'gen_summ': '\"every time i have seen him, he tells me that catholic sisters help keep him catholic,\" she said with a laugh. \"i think part of the reason he is coming is his own nourishment and his support of us.\" . the vice president focused a great deal on what democrats are talking about ahead of the election: the poor and middle class. . clinton\\'s weekend visit was the first time she had been in iowa since 2008, but biden is no stranger to the hawkeye state. . biden has also made a point to acknowledge iowa on a regular basis. . the crowd also featured some of biden\\'s most ardent supporters from his short-lived 2008 presidential campaign. . ', 'true_summ': 'vice president joe biden travels to iowa, a key state in presidential campaigns . he speaks at an event for nuns on the bus, a social justice campaign . biden trails hillary clinton in recent polls for the democratic nomination in 2016 . '}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZR5MRhhD9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}