{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObcP6a53xNS70Z712X3MRf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Summarization/blob/master/summarization_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe_SA3n0I3T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor as mlp\n",
        "from IPython.display import display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTagdmneHA5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "f7dbe295-bac6-4290-8176-f5586a5e08b3"
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1g4I5ARGTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "56c08e76-a53f-4f08-9436-ca0fd631b818"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKpe_KPRLrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change to path to dataset\n",
        "file_name = \"/content/drive/My Drive/Summarization_Pickled_Data/cnn_dataset_1000_labelled.pkl\"\n",
        "stories = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpKVZKCERXbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d90f9161-b848-4672-c19f-b849a86158e8"
      },
      "source": [
        "# displaying the first datapoint\n",
        "# verify correctness of load\n",
        "print(stories[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'story': [\"potomac, maryland (cnn) -- to combat the depression and despair during her 105-day stint in iran's notorious evin prison, haleh esfandiari welcomed all distractions and blocked thoughts of her beloved home and family.\", 'haleh esfandiari talks to iranian media in front of evin prison after her august 21 release.', 'the iranian-american scholar, who was charged with espionage and endangering iranian national security during a december visit to her family, wrote a book in her mind, read newspapers, watched television and exercised voraciously.', '\"i decided either i am going to succumb to despair or i am going to try to make the best of this condition, and the best of this condition was to have a disciplined day,\" she said. \"so i would exercise for many hours, i would read, i would walk a lot, some three to four hours a day -- even in the room, you know, i would pace up and down timing myself.\"', 'the 67-year-old grandmother of two said dwelling on her incarceration, and longing for her family, was disheartening \"so that\\'s why i plunged into exercising, and i wrote a book in my mind on the history and life story of my grandmother. as i would be walking, i would write chapters and edit them in my mind and rewrite it the next day.\" watch an \\'elated\\' esfandiari explain how she passed the time »', 'esfandiari said she was treated \"with respect\" while at evin, but added, \"a prison is a prison.\"', 'esfandiari was allowed to go home last week. she returned to potomac, maryland, on thursday and discussed her arrest and captivity during a saturday interview.', \"though she said she's unsure why she was jailed in evin's political wing, esfandiari believes her iranian captors wanted to know more about the woodrow wilson center for international scholars, the washington-based think tank where she heads the middle east program.\", '\"i think they were trying to found out more about the wilson center -- what it really does, were trying to find out about think tanks in america, foundations in america, the relationship between think tanks, foundations and the government,\" she said.', 'on december 21, the dual iranian-american national traveled to iran to visit her 93-year-old mother, where she visited for nine days. on december 30, she caught a taxi to the airport where she planned to fly home to washington.', 'those plans were altered by three knife-wielding men who stopped her cab, threatened to kill her and stole her luggage and handbag, which contained both of her passports and her airline ticket.', 'esfandiari called her husband, shaul bakhash, back home in maryland and told him to cancel her credit cards and report the stolen passport. the next day, she went to the authorities.', '\"i went to the passport office, and they said that they would like to, somebody wants to talk to you. and that was the beginning of the saga,\" she said.', \"that somebody, according to the wilson center, was an official with iran's ministry of intelligence.\", 'beginning on january 4, esfandiari was subjected to weeks of interrogations, sometimes as many as four a week and some lasting as long as eight hours, according to the wilson center. the questioning, the center said, was \"unpleasant and not free from intimidation and threat.\"', \"she was pressured to make confessions and falsely implicate the wilson center. she once received a threatening phone call. on january 18, she awoke from a nap at her mother's home to find her interrogator and two men -- one of them wielding a video camera -- staring into her bedroom, the wilson center said.\", 'on february 17, the interrogations stopped, but in late april or early may she again began receiving phone calls from the iranian government. on may 7, she was asked to go to the ministry of intelligence the following morning, according to the wilson center.', 'when she arrived, she was put in a car and taken to evin prison. over the next two weeks, iranian media reported that esfandiari was accused of trying to topple the iranian government.', 'later that month, a judiciary spokesperson announced that she was charged with espionage, actions against national security and propaganda against the islamic republic.', '\"it was puzzling for me at first,\" esfandiari told cnn. \"i think there is a concern among certain elements that the united states has planned some kind of velvet revolution in iran, and since they are bogged down in iraq and afghanistan, they won\\'t do it through military. they would do [it] through think tanks and foundations to create a network of people to undermine the regime. i think that is their concern.\"', \"the velvet revolution is the name given to the 1989 bloodless coup that saw czechoslovakia's communist regime overthrown.\", 'in prison, esfandiari was interviewed for an iranian state television documentary, in which she allegedly linked u.s. think tanks and nongovernmental organizations with a \"soft revolution\" against the iranian government.', 'the wilson center quickly denounced the documentary as \"scripted, contrived, and completely without merit.\"', 'the center\\'s president and director, lee hamilton, who has served on the 9/11 commission and iraq study group, also issued a statement, saying the documentary took \"the fabrication of news to a new art form. this is shameful. it cannot be considered a \\'confession\\' by any stretch of the imagination.\"', \"hamilton had written letters to president mahmoud ahmadinejad and majlis speaker shouray-e-islami, to no avail. on june 29, he wrote another letter to grand ayatollah ali khamenei, the supreme leader of iran, pleading for his help in esfandiari's case.\", 'a week later, the former congressman met in new york with iran\\'s representative to the u.n., who delivered a written response from khamenei. the letter, which \"was positive and conveyed respect,\" marked the first time the ayatollah had responded to an american leader, according to the wilson center.', \"esfandiari said she believes she owes her freedom, in part, to hamilton's letter. the iranian government never said why esfandiari was allowed to go home, but on august 21 she was released on a bail of 3 billion iranian rials ($320,000).\", 'esfandiari picked up her passport september 1 and flew to vienna, austria, where her sister lives, the next day. she arrived in the united states on thursday.', '\"the first thing i did, i walked around, walked into the kitchen and started looking at things and say, \\'ok, where is this? this shouldn\\'t be here! that shouldn\\'t be there!\\' \" she said. \"and shaul goes, \\'there she goes again.\\' \"', 'esfandiari said she is \"elated to be home.\"', '\"sleeping in my own bed after eight months, taking a shower in my own bathroom after eight months, walking around the garden,\" she said. \"to see my grandchildren who have grown since i last saw them in those eight months. so it is a fantastic -- it is a fantastic feeling -- and looking back, i am glad this nightmare is over.\" e-mail to a friend'], 'highlights': ['haleh esfandiari says she read, walked, wrote a book in her mind while in prison', 'scholar arrived home thursday after iran forbade her to leave for eight months', 'iranian government never said why they released esfandiari from jail last month', \"wilson center: ayatollah's letter marked first-ever response to american leader\"], 'story_text': 'potomac, maryland (cnn) -- to combat the depression and despair during her 105-day stint in iran\\'s notorious evin prison, haleh esfandiari welcomed all distractions and blocked thoughts of her beloved home and family..haleh esfandiari talks to iranian media in front of evin prison after her august 21 release..the iranian-american scholar, who was charged with espionage and endangering iranian national security during a december visit to her family, wrote a book in her mind, read newspapers, watched television and exercised voraciously..\"i decided either i am going to succumb to despair or i am going to try to make the best of this condition, and the best of this condition was to have a disciplined day,\" she said. \"so i would exercise for many hours, i would read, i would walk a lot, some three to four hours a day -- even in the room, you know, i would pace up and down timing myself.\".the 67-year-old grandmother of two said dwelling on her incarceration, and longing for her family, was disheartening \"so that\\'s why i plunged into exercising, and i wrote a book in my mind on the history and life story of my grandmother. as i would be walking, i would write chapters and edit them in my mind and rewrite it the next day.\" watch an \\'elated\\' esfandiari explain how she passed the time ».esfandiari said she was treated \"with respect\" while at evin, but added, \"a prison is a prison.\".esfandiari was allowed to go home last week. she returned to potomac, maryland, on thursday and discussed her arrest and captivity during a saturday interview..though she said she\\'s unsure why she was jailed in evin\\'s political wing, esfandiari believes her iranian captors wanted to know more about the woodrow wilson center for international scholars, the washington-based think tank where she heads the middle east program..\"i think they were trying to found out more about the wilson center -- what it really does, were trying to find out about think tanks in america, foundations in america, the relationship between think tanks, foundations and the government,\" she said..on december 21, the dual iranian-american national traveled to iran to visit her 93-year-old mother, where she visited for nine days. on december 30, she caught a taxi to the airport where she planned to fly home to washington..those plans were altered by three knife-wielding men who stopped her cab, threatened to kill her and stole her luggage and handbag, which contained both of her passports and her airline ticket..esfandiari called her husband, shaul bakhash, back home in maryland and told him to cancel her credit cards and report the stolen passport. the next day, she went to the authorities..\"i went to the passport office, and they said that they would like to, somebody wants to talk to you. and that was the beginning of the saga,\" she said..that somebody, according to the wilson center, was an official with iran\\'s ministry of intelligence..beginning on january 4, esfandiari was subjected to weeks of interrogations, sometimes as many as four a week and some lasting as long as eight hours, according to the wilson center. the questioning, the center said, was \"unpleasant and not free from intimidation and threat.\".she was pressured to make confessions and falsely implicate the wilson center. she once received a threatening phone call. on january 18, she awoke from a nap at her mother\\'s home to find her interrogator and two men -- one of them wielding a video camera -- staring into her bedroom, the wilson center said..on february 17, the interrogations stopped, but in late april or early may she again began receiving phone calls from the iranian government. on may 7, she was asked to go to the ministry of intelligence the following morning, according to the wilson center..when she arrived, she was put in a car and taken to evin prison. over the next two weeks, iranian media reported that esfandiari was accused of trying to topple the iranian government..later that month, a judiciary spokesperson announced that she was charged with espionage, actions against national security and propaganda against the islamic republic..\"it was puzzling for me at first,\" esfandiari told cnn. \"i think there is a concern among certain elements that the united states has planned some kind of velvet revolution in iran, and since they are bogged down in iraq and afghanistan, they won\\'t do it through military. they would do [it] through think tanks and foundations to create a network of people to undermine the regime. i think that is their concern.\".the velvet revolution is the name given to the 1989 bloodless coup that saw czechoslovakia\\'s communist regime overthrown..in prison, esfandiari was interviewed for an iranian state television documentary, in which she allegedly linked u.s. think tanks and nongovernmental organizations with a \"soft revolution\" against the iranian government..the wilson center quickly denounced the documentary as \"scripted, contrived, and completely without merit.\".the center\\'s president and director, lee hamilton, who has served on the 9/11 commission and iraq study group, also issued a statement, saying the documentary took \"the fabrication of news to a new art form. this is shameful. it cannot be considered a \\'confession\\' by any stretch of the imagination.\".hamilton had written letters to president mahmoud ahmadinejad and majlis speaker shouray-e-islami, to no avail. on june 29, he wrote another letter to grand ayatollah ali khamenei, the supreme leader of iran, pleading for his help in esfandiari\\'s case..a week later, the former congressman met in new york with iran\\'s representative to the u.n., who delivered a written response from khamenei. the letter, which \"was positive and conveyed respect,\" marked the first time the ayatollah had responded to an american leader, according to the wilson center..esfandiari said she believes she owes her freedom, in part, to hamilton\\'s letter. the iranian government never said why esfandiari was allowed to go home, but on august 21 she was released on a bail of 3 billion iranian rials ($320,000)..esfandiari picked up her passport september 1 and flew to vienna, austria, where her sister lives, the next day. she arrived in the united states on thursday..\"the first thing i did, i walked around, walked into the kitchen and started looking at things and say, \\'ok, where is this? this shouldn\\'t be here! that shouldn\\'t be there!\\' \" she said. \"and shaul goes, \\'there she goes again.\\' \".esfandiari said she is \"elated to be home.\".\"sleeping in my own bed after eight months, taking a shower in my own bathroom after eight months, walking around the garden,\" she said. \"to see my grandchildren who have grown since i last saw them in those eight months. so it is a fantastic -- it is a fantastic feeling -- and looking back, i am glad this nightmare is over.\" e-mail to a friend.', 'scores': [0.0014025244075858419, 0.002224693943462096, 0.005610098040124401, 0.0, 0.0022246940174480835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0011947430255763623, 0.0015003749709520506, 0.0, 0.0, 0.0, 0.0015735639960852898, 0.0, 0.0, 0.0, 0.0, 0.00506008844241049, 0.0, 0.0, 0.0, 0.000827129775402439]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsEbuI08RZ9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2804a2e9-4088-4790-9650-0d7826f37b59"
      },
      "source": [
        "# Required Models for glove\n",
        "# in case of errors with conda, use this:\n",
        "# conda install -c conda-forge spacy\n",
        "# this is what worked for me :P\n",
        "\n",
        "!python -m spacy download en\n",
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy link en_core_web_lg en --force\n",
        "\n",
        "# use the large model as the default model for English textual data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=2a1e8fe1183d0944b5a3009a87e62498fe756835f9527038754e95c315d4a3b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ydki3qwh/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-_iuFDvZTvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the processor\n",
        "embedder = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEsDrJHUTOxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic embeddings using averaged glove vectors\n",
        "# using Spacy's large language model\n",
        "def get_embedding(text):\n",
        "    extract = embedder(text)\n",
        "    total_sum = np.zeros(300)\n",
        "    count = 0\n",
        "    for token in extract:\n",
        "        count += 1\n",
        "        total_sum += np.asarray(token.vector)\n",
        "    return total_sum / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26X4T5jHRLpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the inputs and expected outputs\n",
        "train_size = 900\n",
        "val_size = 50\n",
        "test_size = 50\n",
        "\n",
        "def make_set(start_index, size):\n",
        "    count = 0\n",
        "    X_set = []\n",
        "    y_set = []\n",
        "\n",
        "    while count < size:\n",
        "        data = stories[start_index + count]\n",
        "        count += 1\n",
        "\n",
        "        doc_emb = get_embedding(data['story_text'])\n",
        "        # use the function of choice to generate the document embedding\n",
        "\n",
        "        index = 0\n",
        "        for sentence in data['story']:\n",
        "            sent_emb = get_embedding(sentence)\n",
        "            # use the function of choice to generate the sentence embedding\n",
        "\n",
        "            x = np.concatenate((sent_emb, doc_emb))\n",
        "            try:\n",
        "                y = data['scores'][index]\n",
        "            except:\n",
        "                y = 0.0\n",
        "            index += 1\n",
        "\n",
        "            X_set.append(x)\n",
        "            y_set.append(y)\n",
        "\n",
        "    return np.asmatrix(X_set), np.asarray(y_set)\n",
        "\n",
        "X_train, y_train = make_set(0, train_size)\n",
        "X_val, y_val = make_set(train_size, val_size)\n",
        "X_test, y_test = make_set(train_size + val_size, test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY6JkXtWWOwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_values(X, model):\n",
        "    return model.predict(X)\n",
        "\n",
        "def get_loss(pred, y):\n",
        "    return np.linalg.norm(pred - y) / np.shape(y)[0]\n",
        "\n",
        "model_name = \"glove_averaged\"\n",
        "# modify the model name\n",
        "\n",
        "def train(X_train, y_train):\n",
        "    model = mlp(hidden_layer_sizes = (1024, 2048, 1024, 512, 512, 256, 128), max_iter = 1000)\n",
        "    \n",
        "    train_size = np.shape(X_train)[0]\n",
        "\n",
        "    batch_size = int(np.sqrt(train_size))\n",
        "    n_batches = int(4 * (train_size / batch_size))\n",
        "\n",
        "    print(\"Total Number of Training Examples: \" + str(train_size))\n",
        "    print(\"Batch Size: \" + str(batch_size))\n",
        "    print(\"Number of Batches: \" + str(n_batches))\n",
        "\n",
        "    min_loss = 1e20\n",
        "\n",
        "    while(n_batches > 0):\n",
        "        idx = np.random.randint(0, train_size, size = batch_size)\n",
        "\n",
        "        X_select = X_train[idx,:]\n",
        "        y_select = y_train[idx]\n",
        "\n",
        "        model.partial_fit(X_select, y_select)\n",
        "\n",
        "        sentence_predicted_scores = get_values(X_val, model)\n",
        "\n",
        "        loss = get_loss(sentence_predicted_scores, y_val)\n",
        "\n",
        "        # saving best model seen so far\n",
        "        if loss < min_loss:\n",
        "            min_loss = loss\n",
        "            pickle.dump(model, open(model_name + '_best_model', 'wb'))\n",
        "\n",
        "        n_batches -= 1\n",
        "\n",
        "    final_model = pickle.load(open(model_name + '_best_model', 'rb'))\n",
        "    return final_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzWH2VWaQjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cffe27fe-bdd3-4f79-a61b-58e4f9323351"
      },
      "source": [
        "m = train(X_train, 1000 * y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Training Examples: 19223\n",
            "Batch Size: 138\n",
            "Number of Batches: 557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl4yFkiyiTa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameter for similarity threshold\n",
        "theta = 0.95\n",
        "\n",
        "def similarity(A, B):\n",
        "    similarity =  (A @ B.T) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
        "    return similarity\n",
        "\n",
        "def get_top_4(X_doc, y):\n",
        "    order = np.flip(np.argsort(y))\n",
        "    sentence_set = []\n",
        "    for sent_id in order:\n",
        "        if sentence_set == []:\n",
        "            sentence_set.append(order[0])\n",
        "            continue\n",
        "\n",
        "        consider = X_doc[sent_id, :]\n",
        "        flag = 1\n",
        "        for consider_id in sentence_set:\n",
        "            if similarity(X_doc[consider_id, :], consider) > theta:\n",
        "                flag = 0\n",
        "                break\n",
        "\n",
        "        if flag == 1:\n",
        "            sentence_set.append(sent_id)\n",
        "    return sentence_set[0: min(4, len(sentence_set))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_zjPWDVG179",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating object of the ROUGE class\n",
        "rouge = Rouge()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph6OFgGwcewS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "c52f07b4-1a2d-4b83-ba07-c711beeb8d44"
      },
      "source": [
        "# evaluation\n",
        "# testing out each document iteratively\n",
        "# test set: document 'train_size + val_size' onwards\n",
        "\n",
        "def join(lst):\n",
        "    string = \"\"\n",
        "    for elem in lst:\n",
        "        string = string + elem + \" . \"\n",
        "    return string\n",
        "\n",
        "def extract_rouge(rouge_dict):\n",
        "    scores = []\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['r'])\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['r'])\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['r'])\n",
        "\n",
        "    return np.asarray(scores)\n",
        "\n",
        "start_doc_id = train_size + val_size\n",
        "doc_count = len(stories)\n",
        "\n",
        "generated_summary, gold_summary = 0, 0\n",
        "\n",
        "# set the number of documents for testing\n",
        "limit = test_size\n",
        "\n",
        "total = np.zeros(9)\n",
        "# averaging the 9 ROUGE Metrics\n",
        "\n",
        "count = 0\n",
        "\n",
        "while count < min(doc_count, limit):\n",
        "    X_doc = []\n",
        "    y_doc = []\n",
        "    data = stories[start_doc_id + count]\n",
        "    doc_emb = get_embedding(data['story_text'])\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data['story']:\n",
        "        sent_emb = get_embedding(sentence)\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        try:\n",
        "            y = data['scores'][index]\n",
        "        except:\n",
        "            y = 0.0\n",
        "\n",
        "        index += 1\n",
        "\n",
        "        X_doc.append(x)\n",
        "        y_doc.append(y)\n",
        "\n",
        "    X_doc = np.asmatrix(X_doc)\n",
        "    y_doc = np.asarray(y_doc)\n",
        "\n",
        "    sentence_predicted_scores = get_values(X_doc, m)\n",
        "\n",
        "    loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "    # Uncomment to view the test_loss on the sample  \n",
        "    # print(loss)\n",
        "\n",
        "    summary_sent_id = get_top_4(X_doc, sentence_predicted_scores)\n",
        "    # Uncomment to view the indices of chosen sentences\n",
        "    # print(\"Document ID:\", start_doc_id + count, \", Top 5 Sentences:\", summary_sent_id)\n",
        "\n",
        "    # Uncomment to view the top 10 sentences based on Gold Labels\n",
        "    # print(\"Top 10 sentences based on Gold Label\", np.ndarray.tolist(np.flip(np.argsort(y_doc))[0:10]))\n",
        "\n",
        "    gold_summary = join(data['highlights'])\n",
        "    generated_summary = join([data['story'][idx] for idx in summary_sent_id])\n",
        "\n",
        "    scores = rouge.get_scores(generated_summary, gold_summary)[0]\n",
        "    total += extract_rouge(scores)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "averaged = total / test_size\n",
        "\n",
        "predicted = get_values(X_test, m)\n",
        "test_loss = get_loss(y_test, predicted)\n",
        "\n",
        "print(\"Sample Output:\")\n",
        "print(\"Document:\\n\", stories[-1]['story_text'])\n",
        "print(\"Generated Summary:\\n\", generated_summary)\n",
        "print(\"Gold Summary:\\n\", gold_summary)\n",
        "\n",
        "print(\"\\nAll Metrics:\\n\")\n",
        "\n",
        "lst = np.ndarray.tolist(averaged)\n",
        "lst.append(test_loss)\n",
        "\n",
        "df = pd.DataFrame([lst], columns = ['R1-f', 'R1-p', 'R1-r',\n",
        "                                    'R2-f', 'R2-p', 'R2-r',\n",
        "                                    'Rl-f', 'Rl-p', 'Rl-r',\n",
        "                                    'Test Regression Loss'], dtype = float)\n",
        "df.index = ['Averaged Glove Vectors']\n",
        "display(df)\n",
        "\n",
        "# save results into a dataframe file\n",
        "df.to_csv(model_name + '_results.csv')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample Output:\n",
            "Document:\n",
            " -- in the wake of the earthquake in haiti, george clooney and other celebrities have signed on for a telethon to aid the devastated island nation..the oscar-winning actor will take part in a fundraising program to air commercial-free across several networks, mtv announced..\"hope for haiti now\" will air on abc, cbs, nbc, fox, cnn, bet, the cw, hbo, mtv, vh1 and cmt starting at 8 p.m. et/pt and 7 p.m. ct on friday, january 22..mtv said clooney will serve as a host in los angeles, while musician wyclef jean will be in new york, and cnn's anderson cooper will appear from haiti..the two-hour event will feature as-yet-unnamed musical performances and celebrity appearances, as well as live news reports from cnn..it's hollywood's latest philanthropic gesture in reaction to the catastrophic situation in haiti..a celebrity lounge at this weekend's golden globe awards in beverly hills has been turned into a haitian aid fundraiser..medecins sans frontieres says actors angelina jolie and brad pitt have donated $1 million to the group's emergency medical operation as it responds to the disaster..full coverage of the earthquake in haiti.tuesday's 7.0 earthquake has devastated the poverty-stricken country's infrastructure. haitian president rene preval said wednesday that he had heard estimates of up to 50,000 dead but that it was too early to know for sure..damage has closed the port and limited airport operations in the capital city of port-au-prince, and the quake buckled many roads, making it extremely difficult for aid groups to bring in emergency supplies and search for survivors in the rubble..mtv said all proceeds from the telethon will be split evenly among seven relief organizations currently operating in haiti: clinton-bush haiti fund, oxfam america, partners in health, the red cross, unicef and yele haiti foundation and world food programme..\n",
            "Generated Summary:\n",
            " full coverage of the earthquake in haiti . a celebrity lounge at this weekend's golden globe awards in beverly hills has been turned into a haitian aid fundraiser. . damage has closed the port and limited airport operations in the capital city of port-au-prince, and the quake buckled many roads, making it extremely difficult for aid groups to bring in emergency supplies and search for survivors in the rubble. . -- in the wake of the earthquake in haiti, george clooney and other celebrities have signed on for a telethon to aid the devastated island nation. . \n",
            "Gold Summary:\n",
            " fundraising program to be telecast on numerous networks on friday, january 22 . all proceeds will be split among five relief organizations . other celebrities have already launched efforts to aid quake-ravaged haiti . \n",
            "\n",
            "All Metrics:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R1-f</th>\n",
              "      <th>R1-p</th>\n",
              "      <th>R1-r</th>\n",
              "      <th>R2-f</th>\n",
              "      <th>R2-p</th>\n",
              "      <th>R2-r</th>\n",
              "      <th>Rl-f</th>\n",
              "      <th>Rl-p</th>\n",
              "      <th>Rl-r</th>\n",
              "      <th>Test Regression Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Averaged Glove Vectors</th>\n",
              "      <td>20.251263</td>\n",
              "      <td>17.12711</td>\n",
              "      <td>31.217825</td>\n",
              "      <td>4.084392</td>\n",
              "      <td>3.463325</td>\n",
              "      <td>6.40485</td>\n",
              "      <td>20.449854</td>\n",
              "      <td>17.96798</td>\n",
              "      <td>28.451117</td>\n",
              "      <td>0.017769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             R1-f      R1-p  ...       Rl-r  Test Regression Loss\n",
              "Averaged Glove Vectors  20.251263  17.12711  ...  28.451117              0.017769\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZR5MRhhD9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}